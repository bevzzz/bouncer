Models to be used:


Add "dense" layer - every neuron is connected to every other layer
everything needs to be mapped to some outcome

run, predict
load it in a different script
every time the picture need to be processed similarly

224x224 pixels


Videos:
e.g. 100 frames, if ~60% is the person, then set true


Workflow
Load in the proper resolution
split train-test 30%

same preparation as for
rescale to greyscale
2 dimensional cnn


VGG19 from keras

load the model
stop with flatten layer (cuttin layers [-1]) - the last layer is the categorization layer
trainable = False (because you don't want the VGG trained) you want your own cattegories
then you will add your own layer

to feed images, my images need to look like the outputs of the VGG (model.predict())

to_categorical transforms the labels

create own model:
give the last layer of the ouput model
1 layer - input layer == output layer of the vgg

dense layer 4096 acrivation='relu' or 'softmax' for categorical

Normalization layer, dropout 30 percent

FInal layer specifies the exact number of dimension

Reducing layers

Dropout drops out some data, because CNN can easily overfit

after you have the model, with compile function
categorical_crossentropy for the loss-function
select one optimizer
metrics = 'accuracy'

then train model - x=output of get bottleneck - predict on your images scaled

onehot encoded labels

save weights, save the model

predict.classes, feed the bottleneck feature

keras - for nn in general



Cutting videos:
opencv library
research
